{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build a social media sentiment analysis pipeline with scikit-learn\n",
    "\n",
    "*This is Part 5 of 5 in a series on building a sentiment analysis pipeline using scikit-learn. You can find the introduction [here](./sentiment-pipeline-sklearn-1.ipynb).*\n",
    "\n",
    "*Jump to:* \n",
    "\n",
    "* *[**Part 1 - Introduction and requirements**](./sentiment-pipeline-sklearn-1.ipynb)*\n",
    "* *[**Part 2 - Building a basic pipeline**](./sentiment-pipeline-sklearn-2.ipynb)*\n",
    "* *[**Part 3 - Adding a custom function to a pipeline**](./sentiment-pipeline-sklearn-3.ipynb)*\n",
    "* *[**Part 4 - Adding a custom feature to a pipeline with FeatureUnion**](./sentiment-pipeline-sklearn-4.ipynb)*\n",
    "\n",
    "# Part 5 - Hyperparameter tuning in pipelines with GridSearchCV\n",
    "\n",
    "We've done so much so far. Give yourself a hand.\n",
    "\n",
    "Okay, stop giving yourself a hand. Let's move on to the fifth, and final, entry in this series. We know how to build pipelines and add all sorts of fancy features and preprocessing functions in there. Now we're going to do a parameter search to try to find the best pipeline we can.\n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 92 posts from page 1...\n",
      "got 88 posts from page 2...\n",
      "got 88 posts from page 3...\n",
      "got 91 posts from page 4...\n",
      "got 87 posts from page 5...\n",
      "got 89 posts from page 6...\n",
      "got 95 posts from page 7...\n",
      "got 93 posts from page 8...\n",
      "got 86 posts from page 9...\n",
      "got 90 posts from page 10...\n",
      "got all pages - 899 posts in total\n",
      "CPU times: user 853 ms, sys: 348 ms, total: 1.2 s\n",
      "Wall time: 7.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from fetch_twitter_data import fetch_the_data\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = fetch_the_data()\n",
    "X, y = df.text, df.sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "tokenizer = nltk.casual.TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "count_vect = CountVectorizer(tokenizer=tokenizer.tokenize) \n",
    "classifier = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the pipeline\n",
    "\n",
    "This is the same pipeline that we ended up with in [part 4](./sentiment-pipeline-sklearn-4.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn_helpers import pipelinize, pipelinize_feature, get_tweet_length, genericize_mentions\n",
    "\n",
    "sentiment_pipeline = Pipeline([\n",
    "        ('genericize_mentions', pipelinize(genericize_mentions, active=True)),\n",
    "        ('features', FeatureUnion([\n",
    "                    ('vectorizer', count_vect),\n",
    "                    ('post_length', pipelinize_feature(get_tweet_length, active=True))\n",
    "                ])),\n",
    "        ('classifier', classifier)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for golden hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One really sweet thing that scikit-learn has is a nice built-in parameter search class called [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). It plays nicely with the pipelines too. First we'll construct our parameter grid and instantiate our `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn_helpers import train_test_and_evaluate\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "tokenizer_lowercase = nltk.casual.TweetTokenizer(preserve_case=False, reduce_len=False)\n",
    "tokenizer_lowercase_reduce_len = nltk.casual.TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "tokenizer_uppercase = nltk.casual.TweetTokenizer(preserve_case=True, reduce_len=False)\n",
    "tokenizer_uppercase_reduce_len = nltk.casual.TweetTokenizer(preserve_case=True, reduce_len=True)\n",
    "\n",
    "# Our parameter dictionary\n",
    "# You access parameters by giving the dictionary keys of <featurename>__<parameter>\n",
    "# The values of each keys are a list of values that you want to test\n",
    "\n",
    "parameters = {\n",
    "    'genericize_mentions__kw_args': [{'active':False}, {'active':True}], # genericizing mentions on/off\n",
    "    'features__post_length__kw_args': [{'active':False}, {'active':True}], # adding post length feature on/off\n",
    "    'features__vectorizer__ngram_range': [(1,1), (1,2), (1,3)], # ngram range of tokenizer\n",
    "    'features__vectorizer__tokenizer': [tokenizer_lowercase.tokenize, # differing parameters for the TweetTokenizer\n",
    "                                        tokenizer_lowercase_reduce_len.tokenize,\n",
    "                                        tokenizer_uppercase.tokenize,\n",
    "                                        tokenizer_uppercase_reduce_len.tokenize,\n",
    "                                        None], # None will use the default tokenizer\n",
    "    'features__vectorizer__max_df': [0.25, 0.5], # maximum document frequency for the CountVectorizer\n",
    "    'classifier__C': np.logspace(-2, 0, 3) # C value for the LogisticRegression\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(sentiment_pipeline, parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to perform that grid search. It's going to take a while (~3 minutes on my laptop) so kick back and relax. Or pace around and be tense. I'm not going to police the way you spend your downtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 360 candidates, totalling 1080 fits\n",
      "null accuracy: 40.44%\n",
      "accuracy score: 64.00%\n",
      "model is 23.56% more accurate than null accuracy\n",
      "---------------------------------------------------------------------------\n",
      "Confusion Matrix\n",
      "\n",
      "Predicted  negative  neutral  positive  __all__\n",
      "Actual                                         \n",
      "negative         29       15        20       64\n",
      "neutral           8       43        19       70\n",
      "positive          7       12        72       91\n",
      "__all__          44       70       111      225\n",
      "---------------------------------------------------------------------------\n",
      "Classification Report\n",
      "\n",
      "                precision    recall  F1_score support\n",
      "Classes                                              \n",
      "negative         0.659091  0.453125  0.537037      64\n",
      "neutral          0.614286  0.614286  0.614286      70\n",
      "positive         0.648649  0.791209  0.712871      91\n",
      "__avg / total__  0.640928      0.64  0.632185     225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 1080 out of 1080 | elapsed:  2.9min finished\n"
     ]
    }
   ],
   "source": [
    "grid, confusion_matrix = train_test_and_evaluate(grid, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we'll print out what hyperparameters the search found made the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used CasualTokenizer with settings:\n",
      "\tpreserve case: False\n",
      "\treduce length: False\n",
      "best parameters: {\n",
      "    \"features__vectorizer__ngram_range\": [\n",
      "        1, \n",
      "        1\n",
      "    ], \n",
      "    \"features__vectorizer__max_df\": 0.25, \n",
      "    \"classifier__C\": 0.10000000000000001, \n",
      "    \"features__post_length__kw_args\": {\n",
      "        \"active\": true\n",
      "    }, \n",
      "    \"genericize_mentions__kw_args\": {\n",
      "        \"active\": true\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def print_best_params_dict(param_grid):\n",
    "    used_cv = param_grid['features__vectorizer__tokenizer']\n",
    "    if used_cv is None:\n",
    "        params_to_print = grid.best_params_\n",
    "        print 'used default CountVectorizer tokenizer'\n",
    "    else:\n",
    "        params_to_print = {i:grid.best_params_[i] for i in grid.best_params_ if i!='features__vectorizer__tokenizer'}\n",
    "        print 'used CasualTokenizer with settings:'\n",
    "        print '\\tpreserve case: %s' % grid.best_params_['features__vectorizer__tokenizer'].im_self.preserve_case\n",
    "        print '\\treduce length: %s' % grid.best_params_['features__vectorizer__tokenizer'].im_self.reduce_len\n",
    "    print 'best parameters: %s' % json.dumps(params_to_print, indent=4)\n",
    "    \n",
    "print_best_params_dict(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks, `GridSearchCV`! You can also build your own custom scorers for use in parameter grid searches in case you wanted to optimize for a particular metric (such as negative recall), but that's a subject for another time.\n",
    "\n",
    "# Now to summarize what we learned\n",
    "\n",
    "Well, we're finally at the end of the series! You've learned so much - just take a look at this list:\n",
    "\n",
    "1. How to build a basic data pipeline\n",
    "1. How to add text preprocessing inside a pipeline via FunctionTransformers\n",
    "1. How to add new feature columns using FeatureUnion and some funky FunctionTransformer stuff\n",
    "1. How to run a cross-validated parameter grid search on the pipeline\n",
    "\n",
    "So there you have it. A functional, living, breathing scikit-learn pipeline to analyze sentiment. Keep building on to it, adding preprocessing steps, new metafeatures, and tweaking hyperparameters.\n",
    "\n",
    "Hope this was helpful, and thanks for reading.\n",
    "\n",
    "Until next time,\n",
    "\n",
    "#### *Ryan Cranfill*\n",
    "\n",
    "# Thanks to\n",
    "Dylan Lingelbach, Gordon Towne, Nathaniel Meierpolys, and the rest of the crew at Earshot for all the help along the way.\n",
    "\n",
    "*This is Part 5 of 5 in a series on building a sentiment analysis pipeline using scikit-learn. You can find the introduction [here](./sentiment-pipeline-sklearn-1.ipynb). You can't find more parts because they don't exist.*\n",
    "\n",
    "*Jump to:* \n",
    "\n",
    "* *[**Part 1 - Introduction and requirements**](./sentiment-pipeline-sklearn-1.ipynb)*\n",
    "* *[**Part 2 - Building a basic pipeline**](./sentiment-pipeline-sklearn-2.ipynb)*\n",
    "* *[**Part 3 - Adding a custom function to a pipeline**](./sentiment-pipeline-sklearn-3.ipynb)*\n",
    "* *[**Part 4 - Adding a custom feature to a pipeline with FeatureUnion**](./sentiment-pipeline-sklearn-4.ipynb)*"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/bfeb07535373d908f1bba6842e7797d9"
  },
  "gist": {
   "data": {
    "description": "Sentiment Blog Rough Draft",
    "public": false
   },
   "id": "bfeb07535373d908f1bba6842e7797d9"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
